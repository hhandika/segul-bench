---
title: "SEGUL performance benchmark"
author: Heru Handika
output: html_document
---

This file contains all code to analyses SEGUL benchmark results. I use the R base pipe, required R version 4.1. If you are using R version <4.1, change the pipe "|>" to magrittr pipe "%>%".

```{r}
if (!require(pacman)) {
  install.packages(pacman)
}

pacman::p_load(here)
pacman::p_load(ggplot2)
pacman::p_load(readr)
pacman::p_load(dplyr)
pacman::p_load(stringr)
pacman::p_load(RColorBrewer)

source(here::here("R", "utils.R"))
```

## Load results for Handika & Esselstyn. In review

```{r}
file_path <- here("data", "revision_data.csv")
bench <- readr::read_csv(file_path) 
```

## Summarize benchmark results

```{r}
bench_results <- c("Execution_time_secs", "RAM_usage_Mb", "Percent_CPU_usage")

latest_bench.pub <- bench |>
  dplyr::filter(Apps != "Phyluce")

# Check the benchmark for each dataset contains 10 iterations
counts <- latest_bench.pub |>
  dplyr::count(Analyses, Datasets, OS_name, Apps)

mean(counts$n)

summary_by_datasets <- latest_bench.pub |>
  dplyr::group_by(Analyses, Datasets, OS_name, Apps) |>
  dplyr::summarise_at(bench_results, mean)

readr::write_csv(summary_by_datasets, here("results", "mean_bench_by_dataset.csv"))
```

## Mean summary by analyses

```{r}
summary_by_analyses <- latest_bench.pub |>
  dplyr::group_by(Analyses, Apps) |>
  dplyr::summarise_at(bench_results, mean)

readr::write_csv(summary_by_analyses, here("results", "mean_bench_by_analyses.csv"))

segul_val <- summary_by_analyses |>
  filter(Apps == "SEGUL")

segul_ig_val <- summary_by_analyses |>
  filter(Apps == "SEGUL (--datatype ignore)")

segul_exe_concat <- segul_val |>
  filter(Analyses == "Alignment Concatenation")|>
  pull(Execution_time_secs)

segul_ig_exe_concat <- segul_ig_val |>
  filter(Analyses == "Alignment Concatenation") |>
  pull(Execution_time_secs)

segul_mem_concat <- segul_val |>
  filter(Analyses == "Alignment Concatenation") |>
  pull(RAM_usage_Mb)

segul_ig_mem_concat <- segul_ig_val |>
  filter(Analyses == "Alignment Concatenation") |>
  pull(RAM_usage_Mb)

segul_exe_sum <- segul_val |>
  filter(Analyses == "Summary Statistics") |>
  pull(Execution_time_secs)

segul_mem_sum <- segul_val |>
  filter(Analyses == "Summary Statistics") |>
  pull(RAM_usage_Mb)

diff_summary_by_analyses <- summary_by_analyses |>
  dplyr::mutate(diff_SEGUL_exe_con = Execution_time_secs / segul_exe_concat) |>
  # We wanted to see percentage usage of less efficient program uses.
  dplyr::mutate(diff_SEGUL_mem_con = segul_mem_concat / RAM_usage_Mb) |>
  dplyr::mutate(diff_SEGUL_exe_ig_con = Execution_time_secs / segul_ig_exe_concat) |>
  dplyr::mutate(diff_SEGUL_ig_mem_con = RAM_usage_Mb / segul_ig_mem_concat) |>
  dplyr::mutate(diff_SEGUL_exe_sum = Execution_time_secs / segul_exe_sum) |>
  dplyr::mutate(diff_SEGUL_mem_sum = RAM_usage_Mb / segul_mem_sum)

readr::write_csv(diff_summary_by_analyses, here("results", "diff_mean_bench_by_analyses.csv"))
```


## Generate plots using the mean of benchmark results for each datasets

The plots generated below is used for Figure 1 in the manuscript.

```{r}
summary_by_datasets |>
  dplyr::filter(OS_name == "Linux") |>
  ggplot(aes(x = Execution_time_secs, y = RAM_usage_Mb)) +
    geom_point(size = 3, aes(color = Apps, shape = Datasets)) +
    facet_wrap(~ Analyses, scales = "free", ncol = 2) +
    scale_color_manual(values = accessible_palette) +
    scale_shape_manual(values = point_shapes) +
    coord_trans(x = "log") +
    scale_x_continuous(guide = guide_axis(check.overlap = TRUE)) +
    theme_classic() +
    labs(x = "Execution time (secs)", y = "Memory usage (Mb)")

.height <- 6
.width <- 8

ggsave(here("figures", "summary_fig1.png"), width = .width, height = .height, units = "in")
ggsave(here("figures", "summary_fig1.pdf"), width = .width, height = .height, units = "in")
```

